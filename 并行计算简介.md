# 并行计算简介

## 定义
  
  <table><tr><td bgcolor=#F8F8FF>  是指在并行机上，将一个计算问题分解成多个子任务，分配给不同的处理器，各个处理器之间相互协同，并行地执行子任务，从而达到加速求解，或者求解大规模应用问题的目的。</td></tr></table>

## 基本条件
<table><tr><td bgcolor=#F8F8FF>

**并行机**：并行机包含多个处理器核心，这些处理器核心通过特定硬件相互连接，相互通信。

**并行度**：应用问题必须具有并行度，也就是说，应用可以分解为多个子任务，这些子任务可以并行地执行，将一个应用分解为多个子任务的过程，称为并行算法的设计。

**并行编程**：在并行机提供的并行编程环境上，具体实现并行算法，编制并行程序，并运行该程序，从而达到并行求解应用问题的目的。
  
</td></tr></table>

## 基本概念

**粒度**：在并行执行过程中，两次通信之间每个处理器计算工作量大小的一个粗略描述，分为粗粒度和细粒度。

    粒度在并行算法是必不可少的，通常在进程数和效率之间进行选择粒度的大小。一般MPI和OpenMP的并行程序更适合粗粒度并行，而使用CUDA并行程序就需要细粒度。

**并行度**：某一时刻多个处理器上可以同时执行的子任务个数。

    并行度高说明可以使用的处理器多，但不一定有好的效率，需要根据具体问题进行分析。

**加速比**：求解一个问题的最佳串行执行时间与并行算法的执行时间之比。



  实际计算中普遍采用如下的方式计算加速比：
$$S_p(q)={T_s\over T_p(q)}$$
* **加速比**是衡量一个并行算法是否有效的重要指标。其中$T_s$是串行算法在一个处理器上的执行时间，$T_p(q)$是并行算法在***q***个处理器上的执行时间。为度量方便可以取$T_s=T_p(1)$。

* **并行效率**是在加速比的基础上描述单个处理器发挥作用的一个指标，计算公式如下：
$$E_p(q)={S_p(q)\over q}$$

    并行效率高的程序表明充分发挥了处理器的作用。在实际应用中，研究者往往通过综合考虑加速比和并行效率的数值来选择合适的硬件环境。

* **Amdahl 定律**：假设并行计算所需的时间$T_S=1$,$\alpha$是执行该计算所必须的串行部分所占的百分比，则有：
$$S_p(q)={1\over \alpha+(1-\alpha)/q}$$
从这个公式可以得出加速比的一个上限。
$$\lim_{q\rightarrow \infty} S_p(q)={1\over \alpha}$$
    Amdahl定律描述了一般应用问题的加速比上线，给出了固定负载的加速公式。
* **Gustafson 定律**：假设并行计算所需要的时间$T_p=1$，$\alpha$是执行该计算所必须的串行部分所占的百分比，则有：
$$S_p(q)={ \alpha+(1-\alpha)\times q \over 1}$$
    Gustafson定律说明了如何充分利用处理器性能，当我们希望使用更多处理器时，应增大计算问题规模。



## 串行程序性能优化（并行程序性能优化的基础）
* 调用高性能库：BLAS、LAPACK
  、FFTW
* 选择编译器优化选项：-O2、-O3 
* 合理定义数组维数
* 注意嵌套循环次数：数据访问的空间局部性和时间性
* 循环展开
* 数据分块
## 并行程序性能优化
* 设计好的并行算法和通信模式
* 减少通信次数、提高通信粒度
* 多进程通信时尽量使用高效率的聚合通信算法
* 负载平衡
* 减少进程的空闲时间
* 通信与计算的重叠
* 通过引入重复计算来减少通信

## 思考
* 该问题是否可以被并行化？
* 如何对该问题进行分割？
* 任务之间是否需要通讯？
* 是否存在数据依赖？
* 任务之间是否需要同步？
* 是否需要考虑负载均衡？

